{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to profess csv file    \n",
    "#------------------------\n",
    "# get rid of incorrect neuron and non-target neuron for trace file\n",
    "#----------------------------------------------------------------------------------\n",
    "def process_(trace_path, incorrect_neuron_path, position_path):\n",
    "    \n",
    "    #read csv\n",
    "    df = pd.read_csv(trace_path).iloc[1:]\n",
    "    \n",
    "    #profecc column in df file\n",
    "    column_list = df.columns.tolist()\n",
    "    column_list = [column.strip() for column in column_list]\n",
    "    column_list[0] = 'Frame'\n",
    "    df.columns = column_list\n",
    "    \n",
    "    # drop the first row, cell-undecide\n",
    "    #df =df.drop([0])\n",
    "    \n",
    "    #read and process incorrect neuron list\n",
    "    with open(incorrect_neuron_path) as f:\n",
    "        df_in_list = [line.rstrip('\\n') for line in open(incorrect_neuron_path)]\n",
    "    \n",
    "    #fix 78 to 078\n",
    "    new_df_in_list = []\n",
    "    for i in df_in_list:\n",
    "        if len(i) < 3:\n",
    "            sup0 = '0'*(3-len(i))\n",
    "            i = sup0+i\n",
    "        new_df_in_list.append(i)\n",
    "        \n",
    "    new_df_in_list = [\"C\" + neuron for neuron in new_df_in_list]\n",
    "    #print('%i neurons are not correct'%len(new_df_in_list))\n",
    "    \n",
    "    # get cells that are not our target\n",
    "    position = pd.read_csv(position_path, names =['x','y','L'] )\n",
    "    position['C'] = df.columns[1:]\n",
    "    position_no = position[(position['L'] == 0)]\n",
    "    position_no_c_list = position_no['C'].values.tolist()\n",
    "    #print('%i neurons are not our target'%len(position_no_c_list))\n",
    "\n",
    "    # merge incorrect neuron list and non-target neuron list\n",
    "    non_list = list(set(new_df_in_list+position_no_c_list))\n",
    "    #print('%i neurons are removing'%len(non_list))\n",
    "    #print(' ')\n",
    "    # rule out incorrect neurons\n",
    "    df = df.drop(columns = non_list)\n",
    "\n",
    "\n",
    "    #convert object dtype to float\n",
    "    df = df.astype('float')\n",
    "    \n",
    "    #set Frame as index\n",
    "    df = df.set_index('Frame')\n",
    "    return(df)\n",
    "\n",
    "\n",
    "#function to sepatate three sessions of one sample\n",
    "#------------------------\n",
    "\n",
    "#use separate_session(df)[0/1/2] to get each session\n",
    "def separate_session(df):\n",
    "    \n",
    "    check_point = []\n",
    "\n",
    "    frame_list = df.index.values.tolist()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i < len(df)-1:\n",
    "            if (frame_list[i+1] - frame_list[i]) > 3:\n",
    "                check_point.append(frame_list[i+1])\n",
    "\n",
    "\n",
    "    # separate\n",
    "    df_0 = df[df.index < check_point[0] ]\n",
    "    df_1 = df[(df.index < check_point[1]) & (df.index >= check_point[0] ) ]\n",
    "    df_2 = df[(df.index < check_point[2]) & (df.index >= check_point[1] )]\n",
    "    df_3 = df[df.index >= check_point[2]]\n",
    "\n",
    "    return(df_0,df_1,df_2,df_3)\n",
    "\n",
    "\n",
    "#function to get label array\n",
    "#------------------------\n",
    "\n",
    "def process_label(Label_list):\n",
    "    label = pd.read_csv(Label_list, names = 'Label')\n",
    "    label = label[['L']]\n",
    "    label.columns = ['Label']\n",
    "    labels = label.values\n",
    "    return(labels)\n",
    "\n",
    "\n",
    "# process frame list\n",
    "# event file always start from 10.1s, but some trace frame start from 0, some from 741.19\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "def process_frame(df):\n",
    "    # get frame list\n",
    "    frame_list = df.index.values.tolist()\n",
    "    \n",
    "    for i in frame_list:\n",
    "        if i != 0:\n",
    "            a = i-0\n",
    "        else:\n",
    "            a = 0\n",
    "        break\n",
    "        return(a)\n",
    "        break\n",
    "\n",
    "    new_frame_list = [(i-a) for i in frame_list]\n",
    "    \n",
    "    return(new_frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process event_label list\n",
    "# event+label starts from 10, but trace start from 0, deduct 10 from event_start&end time\n",
    "#----------------------------------------------------------------------------------\n",
    "def process_event_interval(df):\n",
    "    event_list = df[['From Second','To Second']].values.tolist()\n",
    "    new_event_list = []\n",
    "    for event in event_list:\n",
    "        new_event = [x -10.01 for x in event]\n",
    "        new_event_list.append(new_event)\n",
    "    return(new_event_list)\n",
    "\n",
    "\n",
    "    \n",
    "# get enevt label for an event file based on different mice and session\n",
    "# for each session, we have separate event file\n",
    "#----------------------------------------------------------------------------------\n",
    "def get_event_label(event_df_0, event_df_1, event_df_2, event_df_3, mice_path):\n",
    "    \n",
    "    #get mice\n",
    "    mice = os.path.basename(mice_path).split('_')[0]    \n",
    "    # get event status list\n",
    "    Event_status_0 = event_df_0['Event'].values.tolist()\n",
    "    Event_status_1 = event_df_1['Event'].values.tolist()\n",
    "    Event_status_2 = event_df_2['Event'].values.tolist()\n",
    "    Event_status_3 = event_df_3['Event'].values.tolist()\n",
    "    Event_status_list = [Event_status_0, Event_status_1, Event_status_2, Event_status_3]\n",
    "    # compact event label list for three sessions\n",
    "    event_label_0 = []\n",
    "    event_label_1 = []\n",
    "    event_label_2 = []\n",
    "    event_label_3 = []\n",
    "    event_label_list = [event_label_0, event_label_1, event_label_2, event_label_3]\n",
    "\n",
    "    \n",
    "    if mice in ['NC128', 'NC139', 'NC297', 'NC298', 'NC308', 'NC314', 'NC315', 'NC463', 'NC476',\n",
    "            'NC102', 'NC103', 'NC114', 'NC296', 'NC313', 'NC462', 'NC464', 'NC468', 'NC475']:\n",
    "        \n",
    "        for i in Event_status_0:   \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_0.append(11)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_0.append(12)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_0.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_0.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_0.append(21)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_0.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_0.append(23)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_0.append(31)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_0.append(32)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_0.append(41)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_0.append(42)\n",
    "            \n",
    "            else:\n",
    "                event_label_0.append(0)\n",
    "                \n",
    "                \n",
    "        for i in Event_status_1:   \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_1.append(11)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_1.append(12)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_1.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_1.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_1.append(21)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_1.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_1.append(23)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_1.append(31)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_1.append(32)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_1.append(41)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_1.append(42)\n",
    "\n",
    "            else:\n",
    "                event_label_1.append(0)\n",
    "\n",
    "        for i in Event_status_2:  \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_2.append(12)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_2.append(11)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_2.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_2.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_2.append(23)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_2.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_2.append(21)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_2.append(32)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_2.append(31)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_2.append(42)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_2.append(41)\n",
    "\n",
    "            else:\n",
    "                event_label_2.append(0)  \n",
    "                \n",
    "        for i in Event_status_3:   \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_3.append(11)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_3.append(12)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_3.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_3.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_3.append(21)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_3.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_3.append(23)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_3.append(31)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_3.append(32)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_3.append(41)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_3.append(42)\n",
    "\n",
    "            else:\n",
    "                event_label_3.append(0)\n",
    "    \n",
    "    #if other mice, just the opposite situation\n",
    "    else:\n",
    "        \n",
    "        for i in Event_status_0:   \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_0.append(11)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_0.append(12)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_0.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_0.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_0.append(21)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_0.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_0.append(23)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_0.append(31)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_0.append(32)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_0.append(41)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_0.append(42)\n",
    "            \n",
    "            else:\n",
    "                event_label_0.append(0)\n",
    "                \n",
    "        for i in Event_status_2:   \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_2.append(11)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_2.append(12)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_2.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_2.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_2.append(21)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_2.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_2.append(23)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_2.append(31)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_2.append(32)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_2.append(41)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_2.append(42)\n",
    "\n",
    "            else:\n",
    "                event_label_2.append(0)\n",
    "                    \n",
    "        for i in Event_status_1:  \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_1.append(12)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_1.append(11)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_1.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_1.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_1.append(23)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_1.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_1.append(21)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_1.append(32)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_1.append(31)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_1.append(42)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_1.append(41)\n",
    "\n",
    "            else:\n",
    "                event_label_1.append(0) \n",
    "\n",
    "\n",
    "        for i in Event_status_3:  \n",
    "            if i == 'Mouse 1 sniffing On s1':\n",
    "                event_label_3.append(12)\n",
    "            elif i == 'Mouse 1 sniffing On s2' :\n",
    "                event_label_3.append(11)\n",
    "            elif i == 'Mouse 1 Grooming':\n",
    "                event_label_3.append(13)\n",
    "\n",
    "            elif i == 'Area:Mouse 1 Center In Box':\n",
    "                event_label_3.append(20)\n",
    "            elif i == 'Area:Mouse 1 Center In Left':\n",
    "                event_label_3.append(23)\n",
    "            elif i == 'Area:Mouse 1 Center In Middle':\n",
    "                event_label_3.append(22)\n",
    "            elif i == 'Area:Mouse 1 Center In Right':\n",
    "                event_label_3.append(21)\n",
    "\n",
    "            elif i == 'Mouse 1 Approaching Area s1':\n",
    "                event_label_3.append(32)\n",
    "            elif i ==  'Mouse 1 Approaching Area s2':\n",
    "                event_label_3.append(31)\n",
    "\n",
    "            elif i ==  'Area:Mouse 1 Nose In s1':\n",
    "                event_label_3.append(42)\n",
    "            elif i ==  'Area:Mouse 1 Nose In s2':\n",
    "                event_label_3.append(41)\n",
    "\n",
    "            else:\n",
    "                event_label_3.append(0)\n",
    "                \n",
    "    return(event_label_0, event_label_1, event_label_2, event_label_3)\n",
    "    \n",
    "    \n",
    "# process events file, add event label for string label\n",
    "#----------------------------------------------------------------------------------\n",
    "def add_event_label(trace_df, event_0_path, event_1_path, event_2_path, event_3_path, mice_path):\n",
    "       \n",
    "    # get separate sessions\n",
    "    df_0,df_1,df_2,df_3 = separate_session(trace_df)\n",
    "    # get df1, df2, df3 frame time list\n",
    "    frame_list_0 = process_frame(df_0)\n",
    "    frame_list_1 = process_frame(df_1)\n",
    "    frame_list_2 = process_frame(df_2)\n",
    "    frame_list_3 = process_frame(df_3)\n",
    "    #get event dataframe\n",
    "    event_df_0 = pd.read_excel(event_0_path, skiprows = 6)\n",
    "    event_df_1 = pd.read_excel(event_1_path, skiprows = 6)\n",
    "    event_df_2 = pd.read_excel(event_2_path, skiprows = 6)\n",
    "    event_df_3 = pd.read_excel(event_3_path, skiprows = 6)\n",
    "    # get event intervals\n",
    "    interval_list_0 = process_event_interval(event_df_0)\n",
    "    interval_list_1 = process_event_interval(event_df_1)\n",
    "    interval_list_2 = process_event_interval(event_df_2)\n",
    "    interval_list_3 = process_event_interval(event_df_3)\n",
    "    # get event label\n",
    "    event_label_0, event_label_1, event_label_2, event_label_3 = get_event_label(event_df_0,\n",
    "                                                                                 event_df_1, event_df_2, event_df_3, mice_path)\n",
    "\n",
    "    \n",
    "    # deal with session 0\n",
    "    frame_label_list_0 = []\n",
    "    for frame in frame_list_0:\n",
    "        frame_label = str()\n",
    "        if frame > 5:\n",
    "            #begin to define frame label\n",
    "            for i in range(len(interval_list_0)):\n",
    "                if min(interval_list_0[i])  <= frame <= max(interval_list_0[i]) :\n",
    "                    frame_label = frame_label+ str(event_label_0[i])\n",
    "\n",
    "        # convert str to int\n",
    "        if len(frame_label) == 0:\n",
    "            frame_label = np.nan\n",
    "        else:\n",
    "            frame_label = int(frame_label)\n",
    "\n",
    "        # append frame label to list\n",
    "        frame_label_list_0.append(frame_label)\n",
    "            \n",
    "    # add label list to trace df \n",
    "    new_df_0 = df_0\n",
    "    new_df_0['Frame_Label']  =  frame_label_list_0\n",
    "    new_df_0 = new_df_0.dropna()\n",
    "    \n",
    "    \n",
    "    # deal with session 1\n",
    "    frame_label_list_1 = []\n",
    "    for frame in frame_list_1:\n",
    "        frame_label = str()\n",
    "        if frame > 5:\n",
    "            #begin to define frame label\n",
    "            for i in range(len(interval_list_1)):\n",
    "                if min(interval_list_1[i])  <= frame <= max(interval_list_1[i]) :\n",
    "                    frame_label = frame_label+ str(event_label_1[i])\n",
    "\n",
    "        # convert str to int\n",
    "        if len(frame_label) == 0:\n",
    "            frame_label = np.nan\n",
    "        else:\n",
    "            frame_label = int(frame_label)\n",
    "\n",
    "        # append frame label to list\n",
    "        frame_label_list_1.append(frame_label)\n",
    "            \n",
    "    # add label list to trace df \n",
    "    new_df_1 = df_1\n",
    "    new_df_1['Frame_Label']  =  frame_label_list_1\n",
    "    new_df_1 = new_df_1.dropna()\n",
    "        \n",
    "    # deal with session 2\n",
    "    frame_label_list_2 = []\n",
    "    for frame in frame_list_2:\n",
    "        frame_label = str()\n",
    "        #begin to define frame label\n",
    "        for i in range(len(interval_list_2)):\n",
    "            if min(interval_list_2[i])  < frame < max(interval_list_2[i]) :\n",
    "                frame_label = frame_label+ str(event_label_2[i])\n",
    "\n",
    "        # convert str to int\n",
    "        if len(frame_label) == 0:\n",
    "            frame_label = np.nan\n",
    "        else:\n",
    "            frame_label = int(frame_label)\n",
    "\n",
    "        # append frame label to list\n",
    "        frame_label_list_2.append(frame_label)\n",
    "            \n",
    "    # add label list to trace df \n",
    "    new_df_2 = df_2\n",
    "    new_df_2['Frame_Label']  =  frame_label_list_2\n",
    "    new_df_2 = new_df_2.dropna()\n",
    "        \n",
    "        \n",
    "    # deal with session 3\n",
    "    frame_label_list_3 = []\n",
    "    for frame in frame_list_3:\n",
    "        frame_label = str()\n",
    "        #begin to define frame label\n",
    "        for i in range(len(interval_list_3)):\n",
    "            if min(interval_list_3[i])  < frame < max(interval_list_3[i]) :\n",
    "                frame_label = frame_label+ str(event_label_3[i])\n",
    "\n",
    "        # convert str to int\n",
    "        if len(frame_label) == 0:\n",
    "            frame_label = np.nan\n",
    "        else:\n",
    "            frame_label = int(frame_label)\n",
    "\n",
    "        # append frame label to list\n",
    "        frame_label_list_3.append(frame_label)\n",
    "            \n",
    "    # add label list to trace df \n",
    "    new_df_3 = df_3\n",
    "    new_df_3['Frame_Label']  =  frame_label_list_3\n",
    "    new_df_3 = new_df_3.dropna()\n",
    "        \n",
    "    \n",
    "    frames = [new_df_0, new_df_1, new_df_2, new_df_3]\n",
    "    new_df = pd.concat(frames)\n",
    "    \n",
    "    #print('The df shape of session 0:',new_df_0.shape)\n",
    "    #print('The df shape of session 1:',new_df_1.shape)\n",
    "    #print('The df shape of session 2:',new_df_2.shape)\n",
    "    #print('The df shape of session 3:',new_df_3.shape)\n",
    "    #print(' ')\n",
    "    \n",
    "    return(new_df, new_df_0, new_df_1, new_df_2, new_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep certain status frrame interval\n",
    "#----------------------------------------------------------------------------------\n",
    "def check_frame_interval(df, which_status_to_check_frame):\n",
    "    \n",
    "    # set up which_status_to_check_frame\n",
    "    \n",
    "    if which_status_to_check_frame == 'social':\n",
    "        which_status_to_check_frame = str(11)\n",
    "    elif which_status_to_check_frame == 'obj':\n",
    "        which_status_to_check_frame = str(12)\n",
    "    elif which_status_to_check_frame == 'grooming':\n",
    "        which_status_to_check_frame = str(13)\n",
    "    elif which_status_to_check_frame == 'social_zone':\n",
    "        which_status_to_check_frame = str(21)\n",
    "    elif which_status_to_check_frame == 'middle_zone':\n",
    "        which_status_to_check_frame = str(22)\n",
    "    elif which_status_to_check_frame == 'obj_zone':\n",
    "        which_status_to_check_frame = str(23)\n",
    "    else:\n",
    "        raise ValueError('Not approved status. choose from: social, obj, social_zone, middle_zone, obj_zone, grooming')\n",
    "\n",
    "    #df = add_event_label(df, event_1_path, event_2_path, event_3_path, mice_path)[which_session]\n",
    "    frame_label_list = df['Frame_Label'].values.tolist()\n",
    "    \n",
    "    # to separate status label, eg:20214111\n",
    "    n = 2\n",
    "    \n",
    "    check_frame_label_list = []\n",
    "    for line in frame_label_list:\n",
    "        line = str(line)\n",
    "        line_list= [line[i:i+n] for i in range(0, len(line), n)]\n",
    "        if which_status_to_check_frame in line_list:\n",
    "            check_frame_label_list.append(1)\n",
    "        else:\n",
    "            check_frame_label_list.append(0)       \n",
    "            \n",
    "    \n",
    "            \n",
    "    df['status'] = check_frame_label_list\n",
    "    df_keep = df[ (df['status'] == 1)]\n",
    "    df_keep = df_keep.drop('status', axis = 1)\n",
    "    df_keep = df_keep.drop('Frame_Label', axis = 1)\n",
    "    \n",
    "    #print('the shape of the dataframe in the status is:', df_keep.shape)\n",
    "    return(df_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get corr between each two cell of a dataframe\n",
    "#----------------------------------------------------------------------------------\n",
    "def corr_list(df, threshold=None):\n",
    "    end_range = df.shape[1]\n",
    "    corr_list = []\n",
    "    \n",
    "    if df.shape[0] >2:\n",
    "        for i in range(end_range):\n",
    "            a = i+1\n",
    "            for a in range(a,end_range):\n",
    "                corr, _ = pearsonr(df.iloc[:,i], df.iloc[:,a])\n",
    "                corr_list.append(corr)\n",
    "          \n",
    "    if threshold:\n",
    "        corrs_mean = np.mean( [x for x in corr_list if x >= threshold])\n",
    "    else:\n",
    "        corrs_mean = np.mean(corr_list)\n",
    "   \n",
    "    return(corr_list)\n",
    "\n",
    "\n",
    "\n",
    "#function to calculate FWHM\n",
    "#------------------------\n",
    "def FWHM(distribute):\n",
    "    \n",
    "    # calculate sigma and mu for best fit\n",
    "    sigma = np.nanstd(distribute) # standard deviation of distribution\n",
    "    mu = np.nanmean(distribute) # mean of the distribution\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    n, bins, patches = ax.hist(distribute, bins=100, density=1)\n",
    "    \n",
    "    # generate best fit curve for the histgram\n",
    "    y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "\n",
    "    # calculate FWHM \n",
    "    peaks, _ = find_peaks(y)\n",
    "    results_half = peak_widths(y, peaks, rel_height=0.5)\n",
    "    FWHM = results_half[0]\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return(FWHM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe every n seconds\n",
    "#----------------------------------------------------------------------------------\n",
    "def splitBasedOnTime(df, timeBin, fps):\n",
    "    \n",
    "    timeFrames = timeBin * fps\n",
    "    \n",
    "    splitDF_list = []\n",
    "    \n",
    "    for i in range(math.floor(df.shape[0]/timeFrames)):\n",
    "\n",
    "        start = i*timeFrames\n",
    "        end = (i+1)*timeFrames\n",
    "\n",
    "        splitDF = df.iloc[start:end]\n",
    "        splitDF_list.append(splitDF)\n",
    "        \n",
    "    return(splitDF_list)\n",
    "\n",
    "\n",
    "# a simple for loop\n",
    "# https://stackoverflow.com/questions/44327999/python-pandas-merge-multiple-dataframes\n",
    "#----------------------------------------------------------------------------------\n",
    "def getFWHMList(df_list, mouse_name, session_index, whichStatus):\n",
    "    \n",
    "    df_FWHM_list = []\n",
    "    \n",
    "    for dfIndex in range(len(df_list)):\n",
    "        \n",
    "        df = df_list[dfIndex]\n",
    "        \n",
    "        df_corrs = corr_list(df)\n",
    "        df_FWHM = FWHM(list(df_corrs))[0]\n",
    "        \n",
    "        dic_ccFWHM = {'mouse_name':mouse_name,\n",
    "                      'session': session_index+1, \n",
    "                      whichStatus+' bin'+str(dfIndex): df_FWHM}\n",
    "        df_ccFWHM = pd.DataFrame.from_dict(dic_ccFWHM, orient='index').T\n",
    "        df_FWHM_list.append(df_ccFWHM)\n",
    "        \n",
    "    if len(df_FWHM_list) >1 :\n",
    "        df_merged = reduce(lambda left,right: pd.merge(left,right,on=['mouse_name','session']), df_FWHM_list)\n",
    "    elif len(df_FWHM_list) ==1:\n",
    "        df_merged = df_FWHM_list[0]\n",
    "    else:\n",
    "        df_merged = pd.DataFrame()\n",
    "\n",
    "    return(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define root path, WT list and Null list\n",
    "# all with frame = 15\n",
    "root_path = r'D:\\zekai_chen\\Mini_Scope\\Processed data\\Social'\n",
    "root_path_onoff = r'C:\\Users\\xiaoqian10\\Desktop\\XiaoqianSun\\Social\\ONOFF_Summary'\n",
    "root_path_incorrect =  r'D:\\zekai_chen\\Mini_Scope\\Processed data\\Social\\Incorrect neuron number'\n",
    "\n",
    "WT_list = ['NC128_WT', \n",
    "           'NC139_WT', 'NC158_WT', 'NC166_WT', 'NC228_WT',\n",
    "           'NC230_WT', 'NC238_WT', 'NC297_WT', 'NC298_WT', \n",
    "           'NC308_WT', 'NC314_WT', 'NC315_WT', 'NC326_WT', 'NC463_WT', 'NC476_WT']\n",
    "\n",
    "WT_incorrect_neuron_list = ['NC128_WT.txt',\n",
    "                            'NC139_WT.txt', 'NC158_WT.txt', 'NC166_WT.txt', 'NC228_WT.txt', \n",
    "                            'NC230_WT.txt', 'NC238_WT.txt', 'NC297_WT.txt', 'NC298_WT.txt', \n",
    "                            'NC308_WT.txt', 'NC314_WT.txt', 'NC315_WT.txt', 'NC326_WT.txt', 'NC463_WT.txt', 'NC476_WT.txt']\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "NULL_list = ['NC102_Null', 'NC103_Null', \n",
    "             'NC114_Null', #'NC149_Null', \n",
    "             'NC159_Null', 'NC227_Null',\n",
    "             'NC232_Null', 'NC239_Null', 'NC296_Null', 'NC303_Null', \n",
    "             'NC304_Null', 'NC313_Null', 'NC462_Null', 'NC468_Null','NC475_Null']\n",
    "\n",
    "NULL_incorrect_neuron_list = ['NC102_NULL.txt', 'NC103_NULL.txt',\n",
    "                              'NC114_NULL.txt', #'NC149_NULL.txt', \n",
    "                              'NC159_NULL.txt', 'NC227_NULL.txt', \n",
    "                              'NC232_NULL.txt', 'NC239_NULL.txt', 'NC296_NULL.txt','NC303_NULL.txt', \n",
    "                              'NC304_NULL.txt', 'NC313_NULL.txt', 'NC462_NULL.txt', 'NC468_NULL.txt','NC475_NULL.txt']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call\n",
    "\n",
    "- individual mouse\n",
    "- save all mouse corr chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT\n",
      "Processing NC128_WT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:358: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:381: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NC139_WT\n",
      "Processing NC158_WT\n",
      "Processing NC166_WT\n",
      "Processing NC228_WT\n",
      "Processing NC230_WT\n",
      "Processing NC238_WT\n",
      "Processing NC297_WT\n",
      "Processing NC298_WT\n",
      "Processing NC308_WT\n",
      "Processing NC314_WT\n",
      "Processing NC315_WT\n",
      "Processing NC326_WT\n",
      "Processing NC463_WT\n",
      "Processing NC476_WT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:83: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:92: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:95: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('WT')\n",
    "\n",
    "timeBin5 = 5\n",
    "timeBin10 = 10\n",
    "timeBin20 = 20\n",
    "\n",
    "WT_social5_list = []\n",
    "WT_social10_list = []\n",
    "WT_social20_list = []\n",
    "WT_object5_list = []\n",
    "WT_object10_list = []\n",
    "WT_object20_list = []\n",
    "\n",
    "for i in range(len(WT_list)):\n",
    "    \n",
    "    mouse_name = WT_list[i]\n",
    "    \n",
    "    print('Processing', mouse_name)\n",
    "    \n",
    "    mice = os.path.join(root_path, mouse_name)\n",
    "    trace = os.path.join(root_path, mouse_name, \"trace.csv\")\n",
    "    position = os.path.join(root_path, mouse_name, \"cells position.csv\")\n",
    "    event0 = os.path.join(root_path, mouse_name, \"event0.xlsx\")\n",
    "    event1 = os.path.join(root_path, mouse_name, \"event1.xlsx\")\n",
    "    event2 = os.path.join(root_path, mouse_name, \"event2.xlsx\")\n",
    "    event3 = os.path.join(root_path, mouse_name, \"event3.xlsx\")\n",
    "    incorrect = os.path.join(root_path_incorrect, WT_incorrect_neuron_list[i])\n",
    "    \n",
    "    # define fps based on mouse_name\n",
    "    if mouse_name.split('_')[0] in ['NC128','NC102', 'NC013']:\n",
    "        fps = 20\n",
    "    else:\n",
    "        fps = 15\n",
    "        \n",
    "    df = process_(trace, incorrect, position) \n",
    "    dfLabeled, session_0, session_1, session_2, session_3 = add_event_label(df, event0, event1, event2, event3, mice)\n",
    "    \n",
    "    session_list = [session_0, session_1, session_2, session_3]\n",
    "    sessionName_list = ['habituation', 'session_1', 'session_2', 'session_3']\n",
    "    \n",
    "    for session_index in range(len(sessionName_list)):\n",
    "        \n",
    "        session = session_list[session_index]\n",
    "        sessionName = sessionName_list[session_index]\n",
    "        \n",
    "        social_df = check_frame_interval(session, 'social')\n",
    "        object_df = check_frame_interval(session, 'obj') \n",
    "        \n",
    "        splitSocial_5 = splitBasedOnTime(social_df, timeBin = timeBin5, fps=fps)\n",
    "        splitObject_5 = splitBasedOnTime(object_df, timeBin = timeBin5, fps=fps)\n",
    "        splitSocial_10 = splitBasedOnTime(social_df, timeBin = timeBin10, fps=fps)\n",
    "        splitObject_10 = splitBasedOnTime(object_df, timeBin = timeBin10, fps=fps)\n",
    "        splitSocial_20 = splitBasedOnTime(social_df, timeBin = timeBin20, fps=fps)\n",
    "        splitObject_20 = splitBasedOnTime(object_df, timeBin = timeBin20, fps=fps)\n",
    "        \n",
    "        \n",
    "        social5_CC_Merged = getFWHMList(splitSocial_5, mouse_name=mouse_name, \n",
    "                                        session_index=session_index, whichStatus='social')\n",
    "        object5_CC_Merged = getFWHMList(splitObject_5, mouse_name=mouse_name, \n",
    "                                        session_index=session_index, whichStatus='object')\n",
    "        social10_CC_Merged = getFWHMList(splitSocial_10,  mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='social')\n",
    "        object10_CC_Merged = getFWHMList(splitObject_10, mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='object')\n",
    "        social20_CC_Merged = getFWHMList(splitSocial_20, mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='social')\n",
    "        object20_CC_Merged = getFWHMList(splitObject_20, mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='object')\n",
    "        \n",
    "            \n",
    "        WT_social5_list.append(social5_CC_Merged)\n",
    "        WT_social10_list.append(social10_CC_Merged)\n",
    "        WT_social20_list.append(social20_CC_Merged)\n",
    "        WT_object5_list.append(object5_CC_Merged)\n",
    "        WT_object10_list.append(object10_CC_Merged)\n",
    "        WT_object20_list.append(object20_CC_Merged)\n",
    "        \n",
    "        \n",
    "        \n",
    "WT_social5 = pd.concat(WT_social5_list)\n",
    "WT_social5.to_csv('WT_social_FWHMTimeBin_5s.csv')\n",
    "\n",
    "WT_social10 = pd.concat(WT_social10_list)\n",
    "WT_social10.to_csv('WT_social_FWHMTimeBin_10s.csv')\n",
    "\n",
    "WT_social20 = pd.concat(WT_social20_list)\n",
    "WT_social20.to_csv('WT_social_FWHMTimeBin_20s.csv')\n",
    "\n",
    "WT_object5 = pd.concat(WT_object5_list)\n",
    "WT_object5.to_csv('WT_object_FWHMTimeBin_5s.csv')\n",
    "\n",
    "WT_object10 = pd.concat(WT_object10_list)\n",
    "WT_object10.to_csv('WT_object_FWHMTimeBin_10s.csv')\n",
    "\n",
    "WT_object20 = pd.concat(WT_object20_list)\n",
    "WT_object20.to_csv('WT_object_FWHMTimeBin_20s.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL\n",
      "Processing NC102_Null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:358: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:381: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NC103_Null\n",
      "Processing NC114_Null\n",
      "Processing NC159_Null\n",
      "Processing NC227_Null\n",
      "Processing NC232_Null\n",
      "Processing NC239_Null\n",
      "Processing NC296_Null\n",
      "Processing NC303_Null\n",
      "Processing NC304_Null\n",
      "Processing NC313_Null\n",
      "Processing NC462_Null\n",
      "Processing NC468_Null\n",
      "Processing NC475_Null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:83: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:92: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\xiaoqian10\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:95: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('NULL')\n",
    "\n",
    "timeBin5 = 5\n",
    "timeBin10 = 10\n",
    "timeBin20 = 20\n",
    "\n",
    "NULL_social5_list = []\n",
    "NULL_social10_list = []\n",
    "NULL_social20_list = []\n",
    "NULL_object5_list = []\n",
    "NULL_object10_list = []\n",
    "NULL_object20_list = []\n",
    "\n",
    "for i in range(len(NULL_list)):\n",
    "    \n",
    "    mouse_name = NULL_list[i]\n",
    "    \n",
    "    print('Processing', mouse_name)\n",
    "    \n",
    "    mice = os.path.join(root_path, mouse_name)\n",
    "    trace = os.path.join(root_path, mouse_name, \"trace.csv\")\n",
    "    position = os.path.join(root_path, mouse_name, \"cells position.csv\")\n",
    "    event0 = os.path.join(root_path, mouse_name, \"event0.xlsx\")\n",
    "    event1 = os.path.join(root_path, mouse_name, \"event1.xlsx\")\n",
    "    event2 = os.path.join(root_path, mouse_name, \"event2.xlsx\")\n",
    "    event3 = os.path.join(root_path, mouse_name, \"event3.xlsx\")\n",
    "    incorrect = os.path.join(root_path_incorrect, NULL_incorrect_neuron_list[i])\n",
    "    \n",
    "    # define fps based on mouse_name\n",
    "    if mouse_name.split('_')[0] in ['NC128','NC102', 'NC013']:\n",
    "        fps = 20\n",
    "    else:\n",
    "        fps = 15\n",
    "        \n",
    "    df = process_(trace, incorrect, position) \n",
    "    dfLabeled, session_0, session_1, session_2, session_3 = add_event_label(df, event0, event1, event2, event3, mice)\n",
    "    \n",
    "    session_list = [session_0, session_1, session_2, session_3]\n",
    "    sessionName_list = ['habituation', 'session_1', 'session_2', 'session_3']\n",
    "    \n",
    "    for session_index in range(len(sessionName_list)):\n",
    "        \n",
    "        session = session_list[session_index]\n",
    "        sessionName = sessionName_list[session_index]\n",
    "        \n",
    "        social_df = check_frame_interval(session, 'social')\n",
    "        object_df = check_frame_interval(session, 'obj') \n",
    "        \n",
    "        splitSocial_5 = splitBasedOnTime(social_df, timeBin = timeBin5, fps=fps)\n",
    "        splitObject_5 = splitBasedOnTime(object_df, timeBin = timeBin5, fps=fps)\n",
    "        splitSocial_10 = splitBasedOnTime(social_df, timeBin = timeBin10, fps=fps)\n",
    "        splitObject_10 = splitBasedOnTime(object_df, timeBin = timeBin10, fps=fps)\n",
    "        splitSocial_20 = splitBasedOnTime(social_df, timeBin = timeBin20, fps=fps)\n",
    "        splitObject_20 = splitBasedOnTime(object_df, timeBin = timeBin20, fps=fps)\n",
    "        \n",
    "        \n",
    "        social5_CC_Merged = getFWHMList(splitSocial_5, mouse_name=mouse_name, \n",
    "                                        session_index=session_index, whichStatus='social')\n",
    "        object5_CC_Merged = getFWHMList(splitObject_5, mouse_name=mouse_name, \n",
    "                                        session_index=session_index, whichStatus='object')\n",
    "        social10_CC_Merged = getFWHMList(splitSocial_10,  mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='social')\n",
    "        object10_CC_Merged = getFWHMList(splitObject_10, mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='object')\n",
    "        social20_CC_Merged = getFWHMList(splitSocial_20, mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='social')\n",
    "        object20_CC_Merged = getFWHMList(splitObject_20, mouse_name=mouse_name, \n",
    "                                         session_index=session_index, whichStatus='object')\n",
    "        \n",
    "            \n",
    "        NULL_social5_list.append(social5_CC_Merged)\n",
    "        NULL_social10_list.append(social10_CC_Merged)\n",
    "        NULL_social20_list.append(social20_CC_Merged)\n",
    "        NULL_object5_list.append(object5_CC_Merged)\n",
    "        NULL_object10_list.append(object10_CC_Merged)\n",
    "        NULL_object20_list.append(object20_CC_Merged)\n",
    "        \n",
    "        \n",
    "        \n",
    "NULL_social5 = pd.concat(NULL_social5_list)\n",
    "NULL_social5.to_csv('NULL_social_FWHMTimeBin_5s.csv')\n",
    "\n",
    "NULL_social10 = pd.concat(NULL_social10_list)\n",
    "NULL_social10.to_csv('NULL_social_FWHMTimeBin_10s.csv')\n",
    "\n",
    "NULL_social20 = pd.concat(NULL_social20_list)\n",
    "NULL_social20.to_csv('NULL_social_FWHMTimeBin_20s.csv')\n",
    "\n",
    "NULL_object5 = pd.concat(NULL_object5_list)\n",
    "NULL_object5.to_csv('NULL_object_FWHMTimeBin_5s.csv')\n",
    "\n",
    "NULL_object10 = pd.concat(NULL_object10_list)\n",
    "NULL_object10.to_csv('NULL_object_FWHMTimeBin_10s.csv')\n",
    "\n",
    "NULL_object20 = pd.concat(NULL_object20_list)\n",
    "NULL_object20.to_csv('NULL_object_FWHMTimeBin_20s.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
